{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/C3Dr7xemCBzFvCCJv2n0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/George-Okello/Ambiguity/blob/main/Ambiguity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zMmcu1zoHYrS"
      },
      "outputs": [],
      "source": [
        "# Install HuggingFace Transformers and Datasets libraries\n",
        "!pip install transformers datasets -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True  # less efficient but reproducible\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "# Load the WSC dataset\n",
        "dataset = load_dataset(\"super_glue\", \"wsc.fixed\")\n",
        "dataset = dataset[\"validation\"]  # Using the validation set for testing\n"
      ],
      "metadata": {
        "id": "mmB0vnycTZjL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a sample\n",
        "sample = dataset[0]\n",
        "for k, v in sample.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTNSZZpdTdPR",
        "outputId": "63d8a233-5be8-40da-f695-20dabadd3988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: Bernard , who had not told the government official that he was less than 21 when he filed for a homestead claim, did not consider that he had done anything dishonest. Still, anyone who knew that he was 19 years old could take his claim away from him .\n",
            "span1_index: 32\n",
            "span2_index: 47\n",
            "span1_text: anyone\n",
            "span2_text: him\n",
            "idx: 0\n",
            "label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LauulyeWTfP2",
        "outputId": "b5f9ccb3-2cf5-43a2-e9de-38d531218932"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "def score_sentence(sentence, target):\n",
        "    # Tokenize and locate the token span\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    # Get score for entire sentence (log prob of each token)\n",
        "    input_ids = inputs.input_ids[0]\n",
        "    log_probs = softmax(logits[0], dim=-1)\n",
        "    token_probs = [log_probs[i, input_ids[i]].item() for i in range(len(input_ids))]\n",
        "    return sum(torch.log(torch.tensor(token_probs))).item()\n"
      ],
      "metadata": {
        "id": "mbT5KzcOT2Tn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = sample[\"text\"]\n",
        "span1 = sample[\"span1_text\"]\n",
        "span2 = sample[\"span2_text\"]\n",
        "\n",
        "# Replace ambiguous pronoun with noun\n",
        "text_with_sub = text.replace(span1, span2)\n",
        "\n",
        "# Score both\n",
        "original_score = score_sentence(text, span1)\n",
        "sub_score = score_sentence(text_with_sub, span2)\n",
        "\n",
        "print(f\"Original: {text}\")\n",
        "print(f\"Modified: {text_with_sub}\")\n",
        "print(f\"Score with pronoun: {original_score:.2f}\")\n",
        "print(f\"Score with candidate: {sub_score:.2f}\")\n",
        "\n",
        "# Prediction\n",
        "prediction = int(sub_score > original_score)\n",
        "print(f\"Predicted label: {prediction}, True label: {sample['label']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDasa-nNT78f",
        "outputId": "f3f1256d-76da-4c42-d86f-06575105c3c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Bernard , who had not told the government official that he was less than 21 when he filed for a homestead claim, did not consider that he had done anything dishonest. Still, anyone who knew that he was 19 years old could take his claim away from him .\n",
            "Modified: Bernard , who had not told the government official that he was less than 21 when he filed for a homestead claim, did not consider that he had done anything dishonest. Still, him who knew that he was 19 years old could take his claim away from him .\n",
            "Score with pronoun: -41.93\n",
            "Score with candidate: -43.39\n",
            "Predicted label: 0, True label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    ex = dataset[i]\n",
        "    if ex['span1_text'] not in ex['text']:\n",
        "        continue  # Skip malformed entries\n",
        "    text = ex['text']\n",
        "    span1 = ex['span1_text']\n",
        "    span2 = ex['span2_text']\n",
        "    label = ex['label']\n",
        "\n",
        "    try:\n",
        "        text_with_sub = text.replace(span1, span2)\n",
        "        original_score = score_sentence(text, span1)\n",
        "        sub_score = score_sentence(text_with_sub, span2)\n",
        "        prediction = int(sub_score > original_score)\n",
        "        correct += (prediction == label)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "accuracy = correct / len(dataset)\n",
        "print(f\"\\nðŸ“Š Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Zan-3EUAQY",
        "outputId": "2fe46629-119d-4b70-bc9b-8293b4d3e98f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Accuracy: 58.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate RoBERTa"
      ],
      "metadata": {
        "id": "MAuPteGMUjRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load model\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
        "roberta_model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\").eval()\n",
        "\n",
        "# Load WSC data\n",
        "wsc = load_dataset(\"super_glue\", \"wsc.fixed\")[\"validation\"]\n"
      ],
      "metadata": {
        "id": "RHBopx4VUlZH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_score_sentence(sentence):\n",
        "    inputs = roberta_tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = roberta_model(**inputs).logits\n",
        "    input_ids = inputs.input_ids[0]\n",
        "    probs = softmax(logits[0], dim=-1)\n",
        "    token_probs = [probs[i, input_ids[i]].item() for i in range(len(input_ids))]\n",
        "    return sum(torch.log(torch.tensor(token_probs))).item()\n"
      ],
      "metadata": {
        "id": "9vHzKMeOVQwt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for ex in wsc:\n",
        "    try:\n",
        "        t = ex['text']\n",
        "        span1 = ex['span1_text']\n",
        "        span2 = ex['span2_text']\n",
        "        if span1 not in t or span2 not in t:\n",
        "            continue\n",
        "        modified = t.replace(span2, span1)\n",
        "        orig_score = roberta_score_sentence(t)\n",
        "        mod_score = roberta_score_sentence(modified)\n",
        "        pred = int(mod_score > orig_score)\n",
        "        if pred == ex['label']:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "print(f\"ðŸ“Š RoBERTa Accuracy: {correct / total * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgSWCKiVVT-f",
        "outputId": "adc07bc4-9616-4723-d6b7-8740054724ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š RoBERTa Accuracy: 57.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_fill(sentence, masked_word):\n",
        "    masked = sentence.replace(masked_word, roberta_tokenizer.mask_token)\n",
        "    inputs = roberta_tokenizer(masked, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = roberta_model(**inputs).logits\n",
        "    mask_token_index = (inputs.input_ids == roberta_tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "    predicted_ids = logits[0, mask_token_index].topk(5).indices[0].tolist()\n",
        "    return [roberta_tokenizer.decode([idx]).strip() for idx in predicted_ids]\n"
      ],
      "metadata": {
        "id": "gFmCBDT1WDJy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = wsc[0]\n",
        "masked_fill(example[\"text\"], example[\"span2_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlFFFh5eWGqY",
        "outputId": "35434b8c-cefd-4b42-e0b6-3343958d0b22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['him', 'Bernard', 'his', 'them', 'her']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate DeBERTa"
      ],
      "metadata": {
        "id": "os5kGouHWzUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load model\n",
        "deberta_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
        "deberta_model = AutoModelForMaskedLM.from_pretrained(\"microsoft/deberta-v3-base\")\n",
        "\n",
        "# Load WSC data\n",
        "wsc = load_dataset(\"super_glue\", \"wsc.fixed\")[\"validation\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EonDvj9XE2h",
        "outputId": "b5320f2c-fb0f-44a3-aab4-f4de20a14989"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deberta_score_sentence(sentence):\n",
        "    inputs = deberta_tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = deberta_model(**inputs).logits\n",
        "    input_ids = inputs.input_ids[0]\n",
        "    probs = softmax(logits[0], dim=-1)\n",
        "    token_probs = [probs[i, input_ids[i]].item() for i in range(len(input_ids))]\n",
        "    return sum(torch.log(torch.tensor(token_probs))).item()"
      ],
      "metadata": {
        "id": "cGNz6WdJXSa4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for ex in wsc:\n",
        "    try:\n",
        "        t = ex['text']\n",
        "        span1 = ex['span1_text']\n",
        "        span2 = ex['span2_text']\n",
        "        if span1 not in t or span2 not in t:\n",
        "            continue\n",
        "        modified = t.replace(span2, span1)\n",
        "        orig_score = deberta_score_sentence(t)\n",
        "        mod_score = deberta_score_sentence(modified)\n",
        "        pred = int(mod_score > orig_score)\n",
        "        if pred == ex['label']:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "print(f\"ðŸ“Š DeBERTa Accuracy: {correct / total * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgjiG3QZXyhF",
        "outputId": "f2d7ce7e-31cd-49bd-b13a-fe545454d5ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š DeBERTa Accuracy: 59.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = wsc[0]\n",
        "masked_fill(example[\"text\"], example[\"span2_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MzlSXeXbxJ0",
        "outputId": "0ef9de9a-0004-47a7-a037-5519aad3a33e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['him', 'Bernard', 'his', 'them', 'her']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use [MASK] Token to Probe Language Understanding"
      ],
      "metadata": {
        "id": "addAYO9EZuhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask_predictions(sentence, target_word, model, tokenizer, top_k=5):\n",
        "    # Replace the target word with the model's mask token\n",
        "    if target_word not in sentence:\n",
        "        raise ValueError(\"Target word not in sentence.\")\n",
        "\n",
        "    masked_sentence = sentence.replace(target_word, tokenizer.mask_token, 1)\n",
        "    inputs = tokenizer(masked_sentence, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs).logits\n",
        "\n",
        "    mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "    top_k_ids = outputs[0, mask_token_index].topk(top_k, dim=-1).indices[0].tolist()\n",
        "    predictions = [tokenizer.decode([idx]).strip() for idx in top_k_ids]\n",
        "\n",
        "    return masked_sentence, predictions\n"
      ],
      "metadata": {
        "id": "TGTz2_OGbBzJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = wsc[0]  # Use the first WSC example\n",
        "sentence = sample[\"text\"]\n",
        "target = sample[\"span2_text\"]\n",
        "\n",
        "masked, guesses = get_mask_predictions(sentence, target, roberta_model, roberta_tokenizer)\n",
        "print(\"Masked sentence:\", masked)\n",
        "print(\"Top predictions:\", guesses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaRpT0Y1bGyU",
        "outputId": "0eb45513-ac36-4fcd-991f-8180fbfdcc32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masked sentence: Bernard , who had not told the government official that he was less than 21 when he filed for a homestead claim, did not consider that he had done anything dishonest. Still, anyone who knew that he was 19 years old could take his claim away from <mask> .\n",
            "Top predictions: ['him', 'Bernard', 'his', 'them', 'her']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeBERTa is better at reasoning about relationships between entities, while RoBERTa is better at predicting what words should appear in contex"
      ],
      "metadata": {
        "id": "50r22fvMd2lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning BERT on WSC (Binary Classification"
      ],
      "metadata": {
        "id": "wrEPywGIbj8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_899a2ycbonp",
        "outputId": "70a91c0c-baa8-4b0c-d4c0-93096d9f4e86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YowyhouniZ37",
        "outputId": "b7ac6436-5368-4487-fac9-b9bed6c501b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"super_glue\", \"wsc\")\n",
        "train_data = dataset['train']\n",
        "val_data = dataset['validation']\n"
      ],
      "metadata": {
        "id": "wQYEroy0icm0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "special_tokens = ['<s1>', '</s1>', '<s2>', '</s2>']\n",
        "tokenizer.add_tokens(special_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6VxuQJrie8x",
        "outputId": "6db8aee0-1caf-4eaf-bb88-f21cdee27dac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "class WSCDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        sentence = example['text']\n",
        "        span1 = example['span1_text']\n",
        "        span2 = example['span2_text']\n",
        "        label = example['label']\n",
        "\n",
        "        # Add special tokens to help model recognize spans\n",
        "        marked_sentence = sentence.replace(span1, f\"<s1>{span1}</s1>\")\n",
        "        marked_sentence = marked_sentence.replace(span2, f\"<s2>{span2}</s2>\")\n",
        "\n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            marked_sentence,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "5HAQw2Cmi6nn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WSCClassifier(nn.Module):\n",
        "    def __init__(self, tokenizer_len):\n",
        "        super().__init__()\n",
        "        self.deberta = AutoModel.from_pretrained('microsoft/deberta-v3-base')\n",
        "        # Resize embeddings for new special tokens\n",
        "        self.deberta.resize_token_embeddings(tokenizer_len)\n",
        "        self.classifier = nn.Linear(self.deberta.config.hidden_size, 2)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Use [CLS] token (position 0) for classification\n",
        "        cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "        cls_token = self.dropout(cls_token)\n",
        "        return self.classifier(cls_token)"
      ],
      "metadata": {
        "id": "RFFjQO6Ti98A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = WSCDataset(train_data, tokenizer)\n",
        "val_dataset = WSCDataset(val_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "3oTcGMoIjA6H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# Clear CUDA cache\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "EgO-z4pml64P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WSCClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size=None):  # Add parameter if needed\n",
        "        super().__init__()\n",
        "        self.deberta = AutoModel.from_pretrained('microsoft/deberta-v3-base')\n",
        "\n",
        "        # Resize embeddings if vocab_size is provided\n",
        "        if vocab_size:\n",
        "            self.deberta.resize_token_embeddings(vocab_size)\n",
        "\n",
        "        self.classifier = nn.Linear(self.deberta.config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.classifier(cls_token)"
      ],
      "metadata": {
        "id": "twI2HKDXl-gi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WSCClassifier().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "EPOCHS = 4\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = correct / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss:.4f} | Train Acc: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpbcD7tDjDH0",
        "outputId": "e80a9fca-21a4-4a9c-ca71-10453403d664"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:34<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 49.1191 | Train Acc: 50.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:27<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train Loss: 48.8857 | Train Acc: 49.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:22<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train Loss: 49.1703 | Train Acc: 50.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:22<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Train Loss: 48.6522 | Train Acc: 50.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "val_acc = correct / len(val_loader.dataset)\n",
        "print(f\"âœ… Validation Accuracy: {val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpwP1PPIoFi8",
        "outputId": "0fdbd9ac-52e4-4819-e841-c792696feffa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Validation Accuracy: 63.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Span-Aware Fine-Tuning"
      ],
      "metadata": {
        "id": "3LKC2IshpkMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers tqdm --quiet\n"
      ],
      "metadata": {
        "id": "TI9rwtd_sAFJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "u5SdW0FpvbHD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpanAwareWSCDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        sentence = example['text']\n",
        "        span1 = example['span1_text']\n",
        "        span2 = example['span2_text']\n",
        "        label = example['label']\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        offset_mapping = encoding['offset_mapping'].squeeze()\n",
        "\n",
        "        span1_mask = torch.zeros_like(input_ids)\n",
        "        span2_mask = torch.zeros_like(input_ids)\n",
        "\n",
        "        span1_start = sentence.find(span1)\n",
        "        span1_end = span1_start + len(span1)\n",
        "        span2_start = sentence.find(span2)\n",
        "        span2_end = span2_start + len(span2)\n",
        "\n",
        "        for i, (start, end) in enumerate(offset_mapping):\n",
        "            if start == 0 and end == 0:\n",
        "                continue\n",
        "\n",
        "            if not (end <= span1_start or start >= span1_end):\n",
        "                span1_mask[i] = 1\n",
        "\n",
        "            if not (end <= span2_start or start >= span2_end):\n",
        "                span2_mask[i] = 1\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'span1_mask': span1_mask,\n",
        "            'span2_mask': span2_mask,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Hm9XCbFTvhRC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses DeBERTa as a base encoder and adds:\n",
        "- Multi-head attention over each span\n",
        "- Cross-attention between the two spans\n",
        "- A classifier over the combined representations of `[CLS]`, span1, span2, and their interaction\n"
      ],
      "metadata": {
        "id": "MyadDZdWv1jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpanAwareWSCClassifier(nn.Module):\n",
        "    def __init__(self, model_name='microsoft/deberta-v3-base', hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.deberta = AutoModel.from_pretrained(model_name)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.span1_attention = nn.MultiheadAttention(hidden_size, 8, batch_first=True)\n",
        "        self.span2_attention = nn.MultiheadAttention(hidden_size, 8, batch_first=True)\n",
        "        self.cross_attention = nn.MultiheadAttention(hidden_size, 8, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size * 4)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 4, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, span1_mask, span2_mask):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "        cls_repr = hidden_states[:, 0, :]\n",
        "\n",
        "        span1_repr = self.get_span_representation(hidden_states, span1_mask, self.span1_attention)\n",
        "        span2_repr = self.get_span_representation(hidden_states, span2_mask, self.span2_attention)\n",
        "        interaction_repr = self.get_interaction_representation(span1_repr, span2_repr)\n",
        "\n",
        "        combined = torch.cat([cls_repr, span1_repr, span2_repr, interaction_repr], dim=-1)\n",
        "        combined = self.layer_norm(combined)\n",
        "        combined = self.dropout(combined)\n",
        "        return self.classifier(combined)\n",
        "\n",
        "    def get_span_representation(self, hidden_states, span_mask, attention_layer, return_attention=False):\n",
        "        batch_size, seq_len, hidden_size = hidden_states.size()\n",
        "        span_attention_mask = span_mask.float()\n",
        "        has_span = span_attention_mask.sum(dim=1, keepdim=True) > 0\n",
        "\n",
        "        attn_output, attn_weights = attention_layer(\n",
        "            hidden_states,\n",
        "            hidden_states,\n",
        "            hidden_states,\n",
        "            key_padding_mask=(1 - span_attention_mask).bool(),\n",
        "            need_weights=True,\n",
        "            average_attn_weights=True\n",
        "        )\n",
        "\n",
        "        span_lengths = span_attention_mask.sum(dim=1, keepdim=True).clamp(min=1)\n",
        "        span_repr = (attn_output * span_attention_mask.unsqueeze(-1)).sum(dim=1) / span_lengths\n",
        "        cls_repr = hidden_states[:, 0, :]\n",
        "        final_repr = torch.where(has_span, span_repr, cls_repr)\n",
        "\n",
        "        if return_attention:\n",
        "            return final_repr, attn_weights\n",
        "        return final_repr\n",
        "\n",
        "    def get_interaction_representation(self, span1_repr, span2_repr):\n",
        "        interaction, _ = self.cross_attention(\n",
        "            span1_repr.unsqueeze(1),\n",
        "            span2_repr.unsqueeze(1),\n",
        "            span2_repr.unsqueeze(1)\n",
        "        )\n",
        "        return interaction.squeeze(1)\n"
      ],
      "metadata": {
        "id": "d6VEKLg3v3hd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function handles the full training loop including:\n",
        "- Data loading\n",
        "- Accuracy and loss tracking\n",
        "- Learning rate scheduling\n",
        "- Model checkpointing\n"
      ],
      "metadata": {
        "id": "V8Ksc0giv9IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_span_aware_model(train_data, val_data, tokenizer, device, epochs=10, patience=3):\n",
        "    train_dataset = SpanAwareWSCDataset(train_data, tokenizer)\n",
        "    val_dataset = SpanAwareWSCDataset(val_data, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "    model = SpanAwareWSCClassifier().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"ðŸš€ Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            span1_mask = batch['span1_mask'].to(device)\n",
        "            span2_mask = batch['span2_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids, attention_mask, span1_mask, span2_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        val_loss, val_correct, val_total = 0, 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                span1_mask = batch['span1_mask'].to(device)\n",
        "                span2_mask = batch['span2_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                logits = model(input_ids, attention_mask, span1_mask, span2_mask)\n",
        "                val_loss += criterion(logits, labels).item()\n",
        "                preds = logits.argmax(dim=1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"\\nðŸ“Š Epoch {epoch+1}: Train Acc = {train_acc*100:.2f}% | Val Acc = {val_acc*100:.2f}%\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_span_aware_wsc_model.pth')\n",
        "            print(\"âœ… New best model saved!\")\n",
        "            patience_counter = 0  # reset counter\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"âš ï¸  No improvement. Patience: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"ðŸ›‘ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"\\nðŸ Training complete! Best Val Accuracy: {best_val_acc*100:.2f}%\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "3xguI5Nsv-md"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = train_span_aware_model(train_data, val_data, tokenizer, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRNWxw95wYW_",
        "outputId": "3f9b33c9-fc91-44fe-ccea-c76f363fd1f9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Model has 193,286,402 parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:43<00:00,  1.62it/s]\n",
            "Epoch 1/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  6.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 1: Train Acc = 49.28% | Val Acc = 36.54%\n",
            "âœ… New best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.65it/s]\n",
            "Epoch 2/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 2: Train Acc = 51.44% | Val Acc = 36.54%\n",
            "âš ï¸  No improvement. Patience: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.68it/s]\n",
            "Epoch 3/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 3: Train Acc = 51.62% | Val Acc = 63.46%\n",
            "âœ… New best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:33<00:00,  2.06it/s]\n",
            "Epoch 4/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 4: Train Acc = 51.26% | Val Acc = 63.46%\n",
            "âš ï¸  No improvement. Patience: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.65it/s]\n",
            "Epoch 5/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 5: Train Acc = 52.35% | Val Acc = 63.46%\n",
            "âš ï¸  No improvement. Patience: 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.68it/s]\n",
            "Epoch 6/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 6: Train Acc = 53.07% | Val Acc = 63.46%\n",
            "âš ï¸  No improvement. Patience: 3/3\n",
            "ðŸ›‘ Early stopping triggered.\n",
            "\n",
            "ðŸ Training complete! Best Val Accuracy: 63.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This utility helps visualize which tokens in the input contributed most to the modelâ€™s decision. Weâ€™ll use the attention weights from the span attention heads and CLS token relevance as a rough proxy (similar to Grad-CAM but adapted for transformers).\n"
      ],
      "metadata": {
        "id": "AoLP3Leixj5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_attention(tokenizer, input_ids, span1_mask, span2_mask, attention_scores, title=\"Attention\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    attention_scores = attention_scores.detach().cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(len(tokens) * 0.3, 1.5))\n",
        "    sns.heatmap([attention_scores], xticklabels=tokens, cmap=\"Blues\", cbar=True, linewidths=0.5, annot=False)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(title)\n",
        "    plt.yticks([])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "hj5e2qmixh81"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_visualize(model, tokenizer, sentence, span1_text, span2_text, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize input\n",
        "    encoding = tokenizer(\n",
        "        sentence,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt',\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    offset_mapping = encoding['offset_mapping'].squeeze()\n",
        "\n",
        "    # Prepare span masks\n",
        "    span1_mask = torch.zeros_like(input_ids)\n",
        "    span2_mask = torch.zeros_like(input_ids)\n",
        "\n",
        "    s1_start = sentence.find(span1_text)\n",
        "    s1_end = s1_start + len(span1_text)\n",
        "    s2_start = sentence.find(span2_text)\n",
        "    s2_end = s2_start + len(span2_text)\n",
        "\n",
        "    for i, (start, end) in enumerate(offset_mapping):\n",
        "        if start == 0 and end == 0:\n",
        "            continue\n",
        "        if not (end <= s1_start or start >= s1_end):\n",
        "            span1_mask[0, i] = 1\n",
        "        if not (end <= s2_start or start >= s2_end):\n",
        "            span2_mask[0, i] = 1\n",
        "\n",
        "    # Forward pass with attention extraction\n",
        "    with torch.no_grad():\n",
        "        hidden_states = model.deberta(input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "\n",
        "        s1_repr, s1_att = model.get_span_representation(hidden_states, span1_mask, model.span1_attention, return_attention=True)\n",
        "        s2_repr, s2_att = model.get_span_representation(hidden_states, span2_mask, model.span2_attention, return_attention=True)\n",
        "        interaction_repr = model.get_interaction_representation(s1_repr, s2_repr)\n",
        "        cls_repr = hidden_states[:, 0, :]\n",
        "\n",
        "        combined = torch.cat([cls_repr, s1_repr, s2_repr, interaction_repr], dim=-1)\n",
        "        combined = model.layer_norm(combined)\n",
        "        combined = model.dropout(combined)\n",
        "        logits = model.classifier(combined)\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1).squeeze().cpu()\n",
        "        pred = torch.argmax(probs).item()\n",
        "        label_str = \"Same Entity\" if pred == 1 else \"Different Entities\"\n",
        "\n",
        "        print(f\"ðŸ” Sentence: {sentence}\")\n",
        "        print(f\"ðŸ‘¤ Span1: \\\"{span1_text}\\\" | ðŸ‘¤ Span2: \\\"{span2_text}\\\"\")\n",
        "        print(f\"ðŸ§  Prediction: {label_str} (Confidence: {probs[pred]:.2f})\")\n",
        "\n",
        "    visualize_attention(tokenizer, input_ids[0], span1_mask[0], span2_mask[0], s1_att[0].mean(0), title=\"Span 1 Attention\")\n",
        "    visualize_attention(tokenizer, input_ids[0], span1_mask[0], span2_mask[0], s2_att[0].mean(0), title=\"Span 2 Attention\")\n"
      ],
      "metadata": {
        "id": "tVHelktkxtxX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model if not already in memory\n",
        "model.load_state_dict(torch.load('best_span_aware_wsc_model.pth', map_location=device))\n",
        "\n",
        "# Example interactive prediction\n",
        "predict_and_visualize(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    sentence=\"The trophy wouldn't fit in the suitcase because it was too big.\",\n",
        "    span1_text=\"trophy\",\n",
        "    span2_text=\"it\",\n",
        "    device=device\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "0BUF-MYryUNW",
        "outputId": "88833add-f23b-47be-ddf3-d694482e64bf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Sentence: The trophy wouldn't fit in the suitcase because it was too big.\n",
            "ðŸ‘¤ Span1: \"trophy\" | ðŸ‘¤ Span2: \"it\"\n",
            "ðŸ§  Prediction: Different Entities (Confidence: 0.58)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3840x150 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3840x150 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}